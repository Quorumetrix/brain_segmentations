{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Loading Workflow Metadata.ipynb\n",
    "\n",
    "As an interface between the analysis pipeline and the Napari GUI environment, using the workflow assistant. \n",
    "\n",
    "The steps of the image analysis pipeline are exported as a \n",
    ".py file and/or yaml file, containing the order and parameters for the steps used. \n",
    "\n",
    "This notebook will import that info and turn it into a processing pipeline. \n",
    "\n",
    "Ultimately, the goal is to have a user generated metadatafile for each experimental replicate, with parameters adapted to segmentaing cells as best possible from a sample of cropped regions from multiple image planes. \n",
    "\n",
    "These replicate-specific parameters will be saved into a folder, and loaded as a part of this analysis pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example filepaths for testing\n",
    "\n",
    "workflow_dir = 'M://Brain_Registration/napari-clesperanto/'\n",
    "\n",
    "workflow_py = 'test_workflow.py'\n",
    "workflow_yaml = 'test_workflow.yaml'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def read_yaml_file(filename):\n",
    "    with open(filename, 'r') as stream:\n",
    "        try:\n",
    "            data = yaml.safe_load(stream)\n",
    "\n",
    "            print(data)\n",
    "            return data\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not determine a constructor for the tag 'tag:yaml.org,2002:python/object:napari_workflows._workflow.Workflow'\n",
      "  in \"M://Brain_Registration/napari-clesperanto/test_workflow.yaml\", line 1, column 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Workflow_constructor(loader, node):\n",
    "    value = loader.construct_mapping(node)\n",
    "    # Instantiate your Workflow object based on the loaded values\n",
    "    obj = napari_workflows._workflow.Workflow(value)\n",
    "    return obj\n",
    "\n",
    "# Register the constructor for the Workflow object\n",
    "yaml.SafeLoader.add_constructor(u'!!python/object:napari_workflows._workflow.Workflow', Workflow_constructor)\n",
    "\n",
    "# Now, you should be able to load your yaml file using the `safe_load()` function:\n",
    "data = read_yaml_file(workflow_dir+workflow_yaml)\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ruamel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\Documents\\Professional\\Jupyter notebooks\\Projects\\Iordonova_lab\\brain_segmentations\\Notebooks\\Test Loading Workflow Metadata.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mruamel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39myaml\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_workflow_yaml\u001b[39m(file_path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# Create YAML loader\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     yaml \u001b[39m=\u001b[39m ruamel\u001b[39m.\u001b[39myaml\u001b[39m.\u001b[39mYAML(typ\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msafe\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# 'safe' means it won't load any Python objects\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ruamel'"
     ]
    }
   ],
   "source": [
    "import ruamel.yaml\n",
    "\n",
    "def parse_workflow_yaml(file_path):\n",
    "    # Create YAML loader\n",
    "    yaml = ruamel.yaml.YAML(typ='safe')  # 'safe' means it won't load any Python objects\n",
    "\n",
    "    # Load YAML file\n",
    "    with open(file_path) as file:\n",
    "        data = yaml.load(file)\n",
    "\n",
    "    # Extract tasks\n",
    "    tasks = data.get('_tasks', {})\n",
    "\n",
    "    # Initialize empty dict for parsed tasks\n",
    "    parsed_tasks = {}\n",
    "\n",
    "    # Iterate over tasks\n",
    "    for task_name, task_data in tasks.items():\n",
    "        # Skip if not a tuple (which indicates a function call)\n",
    "        if not isinstance(task_data, list):\n",
    "            continue\n",
    "\n",
    "        # Extract function name and parameters\n",
    "        function_name = task_data[0].split('.')[-1]  # Get last part of function name\n",
    "        parameters = task_data[1:]\n",
    "\n",
    "        # Convert 'null' to None\n",
    "        parameters = [None if param == 'null' else param for param in parameters]\n",
    "\n",
    "        # Save parsed task\n",
    "        parsed_tasks[task_name] = {\n",
    "            'function_name': function_name,\n",
    "            'parameters': parameters,\n",
    "        }\n",
    "\n",
    "    return parsed_tasks\n",
    "\n",
    "data = parse_workflow_yaml(workflow_dir+workflow_yaml)\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tasks': {'function_name': '',\n",
       "  'parameters': ['Result of top_hat_box (clesperanto)',\n",
       "   None,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   'Result of top_hat_box (clesperanto)',\n",
       "   '356850_415210_044800_cropped_0',\n",
       "   None,\n",
       "   2.0,\n",
       "   2.0,\n",
       "   0.0,\n",
       "   'Result of threshold_otsu (clesperanto)',\n",
       "   None,\n",
       "   2.0,\n",
       "   2.0]}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "def parse_workflow_yaml(file_path):\n",
    "    tasks = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        task_name = None\n",
    "        for line in lines:\n",
    "            if \"!!python\" not in line:\n",
    "                if \":\" in line and line[0] != \" \":\n",
    "                    task_name = line.split(\":\")[0].strip()\n",
    "                    tasks[task_name] = {'function_name': '', 'parameters': []}\n",
    "                elif task_name:\n",
    "                    if \"!!python/name\" in line:\n",
    "                        tasks[task_name]['function_name'] = line.split(\"''\")[0].split(\".\")[-1].strip()\n",
    "                    else:\n",
    "                        param = line.strip().strip('-').strip()\n",
    "                        if param == 'null':\n",
    "                            param = None\n",
    "                        elif param.replace('.','').isdigit():\n",
    "                            param = float(param)\n",
    "                        tasks[task_name]['parameters'].append(param)\n",
    "    return tasks\n",
    "\n",
    "data = parse_workflow_yaml(workflow_dir+workflow_yaml)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Documents\\Professional\\Jupyter notebooks\\Projects\\Iordonova_lab\\brain_segmentations\\Notebooks\\Test Loading Workflow Metadata.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                 variables[task_name] \u001b[39m=\u001b[39m command_name\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m commands\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#X13sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m data \u001b[39m=\u001b[39m parse_workflow_yaml(workflow_dir\u001b[39m+\u001b[39;49mworkflow_yaml)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#X13sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m display(data)\n",
      "\u001b[1;32me:\\Documents\\Professional\\Jupyter notebooks\\Projects\\Iordonova_lab\\brain_segmentations\\Notebooks\\Test Loading Workflow Metadata.ipynb Cell 7\u001b[0m in \u001b[0;36mparse_workflow_yaml\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m task_name, rest \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m rest \u001b[39m=\u001b[39m rest\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m command_name \u001b[39m=\u001b[39m rest[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m params \u001b[39m=\u001b[39m [param\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m rest[\u001b[39m2\u001b[39m:]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/Notebooks/Test%20Loading%20Workflow%20Metadata.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# replace parameter names with corresponding variable names\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def parse_workflow_yaml(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # initialize the list of commands and the dictionary of variables\n",
    "    commands = []\n",
    "    variables = {}\n",
    "\n",
    "    # iterate over the lines in the file\n",
    "    for line in lines:\n",
    "        if line.startswith(\"  \"):  # if the line is indented, it's a task\n",
    "            if \"!!python/tuple\" in line:  # if it's a command\n",
    "                # extract the command name and parameters\n",
    "                line = line.replace(\"!!python/tuple\", \"\")\n",
    "                line = line.replace(\"!!python/name:\", \"\")\n",
    "                line = line.strip()\n",
    "                task_name, rest = line.split(\":\")\n",
    "                rest = rest.split(\"-\")\n",
    "                command_name = rest[1].strip()\n",
    "                params = [param.strip() for param in rest[2:]]\n",
    "\n",
    "                # replace parameter names with corresponding variable names\n",
    "                for i in range(len(params)):\n",
    "                    if params[i] in variables:\n",
    "                        params[i] = variables[params[i]]\n",
    "\n",
    "                # add the command to the list of commands\n",
    "                commands.append({\n",
    "                    \"command_name\": command_name,\n",
    "                    \"params\": params\n",
    "                })\n",
    "\n",
    "                # add the output variable to the dictionary of variables\n",
    "                variables[task_name] = command_name\n",
    "\n",
    "\n",
    "    return commands\n",
    "\n",
    "data = parse_workflow_yaml(workflow_dir+workflow_yaml)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_python_script(data, script_filename):\n",
    "    with open(script_filename, 'w') as script_file:\n",
    "        script_file.write(\"import pyclesperanto_prototype as cle\\n\")\n",
    "        script_file.write(\"from skimage.io import imread\\n\")\n",
    "        script_file.write(\"from napari import Viewer\\n\\n\")\n",
    "        script_file.write(\"def pipeline(input_image):\\n\")\n",
    "        script_file.write(\"\\tviewer = Viewer()\\n\\n\")\n",
    "\n",
    "        for key, value in data.items():\n",
    "\n",
    "            print(key, value)\n",
    "            if isinstance(value, list) and len(value) > 0 and \"pyclesperanto_prototype\" in value[0]:\n",
    "                # write the name of the function and open bracket\n",
    "                script_file.write(\"\\t\" + key + \" = \" + value[0].split(\".\")[-1] + \"(\")\n",
    "\n",
    "                # write the parameters of the function\n",
    "                for param in value[1:]:\n",
    "                    if isinstance(param, str):\n",
    "                        if param.isnumeric():\n",
    "                            script_file.write(param + \", \")\n",
    "                        else:\n",
    "                            script_file.write(\"'\" + param + \"', \")\n",
    "                    elif param is None:\n",
    "                        script_file.write(\"None, \")\n",
    "                    else:\n",
    "                        script_file.write(str(param) + \", \")\n",
    "                \n",
    "                # remove last \", \" and close bracket\n",
    "                script_file.seek(script_file.tell() - 2, os.SEEK_SET)\n",
    "                script_file.write(\")\\n\")\n",
    "                \n",
    "                # add image to viewer\n",
    "                script_file.write(\"\\tviewer.add_image(\" + key + \", name='\" + key + \"')\\n\\n\")\n",
    "\n",
    "        script_file.write(\"\\treturn viewer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_tasks {'function_name': '', 'parameters': ['Result of top_hat_box (clesperanto)', None, 1.0, 1.0, 0.0, 'Result of top_hat_box (clesperanto)', '356850_415210_044800_cropped_0', None, 2.0, 2.0, 0.0, 'Result of threshold_otsu (clesperanto)', None, 2.0, 2.0]}\n"
     ]
    }
   ],
   "source": [
    "# Write the Python script\n",
    "write_python_script(data, \"generated_pipeline_script.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_segmentations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
