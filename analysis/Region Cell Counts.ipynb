{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region Cell Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_folder defined in config. Be careful in the future! Iordanova_06082022_SOC-R9-F_NeuN-cFOS/\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage import io, transform\n",
    "from skimage.util import img_as_float32\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "# Module imports\n",
    "import sys\n",
    "sys.path.append('E://Documents/Professional/Jupyter notebooks/Projects/Iordonova_lab/')\n",
    "# sys.path.append('brain_segmentations')\n",
    "\n",
    "from brain_segmentations.config import *\n",
    "from brain_segmentations.preprocessing.file_io import *\n",
    "from brain_segmentations.registration.registration import *\n",
    "from brain_segmentations.segmentation.segmentation import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and variables\n",
    "\n",
    "region_id = 406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "# label_path = 'M://Brain_Registration/brainreg_napari_output/full_brain_dowsampled_tiff_chris/'\n",
    "label_path = 'M://Brain_Registration/brainreg_napari_output/may10_20ds_fullz_preds/'\n",
    "\n",
    "atlas_identifier = 'registered_atlas_original_orientation'\n",
    "atlas_filename = label_path + atlas_identifier + '.tiff'\n",
    "\n",
    "fullres_folder = 'Z://Collaboration_data/Iordonova_lab/Iordanova_06082022_SOC-R9-F_NeuN-cFOS/561nm_NeuN/'\n",
    "fos_folder = 'Z://Collaboration_data/Iordonova_lab/Iordanova_06082022_SOC-R9-F_NeuN-cFOS/647nm_cFOS/'\n",
    "ds_folder = 'M://Brain_Registration/downsampled_20/neun/'\n",
    "\n",
    "# Get a list of all tif files in the folder \n",
    "identifiers = [f[:-4] for f in os.listdir(fullres_folder) if f.endswith('.tif')]\n",
    "\n",
    "# slice_identifier = '356850_415210_029200'\n",
    "slice_identifier = '356850_415210_044800' # Eventually will on a loop over all slices in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(738, 507, 284)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the reference atlas in image coordinates\n",
    "labels = io.imread(atlas_filename).astype(np.int32) \n",
    "\n",
    "# Reorder the labels to be more intuitive, where the z-axis is the 3rd dimension\n",
    "labels = np.moveaxis(labels, 0, -1)\n",
    "\n",
    "lab_xdim, lab_ydim, lab_zdim = labels.shape\n",
    "labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load an original-resolution tif image.\n",
    "\n",
    "# tif_filename = fullres_folder + slice_identifier + '.tif'\n",
    "\n",
    "\n",
    "# '''NOTE:\n",
    "# Eventuyally we'll replace all fs_img with neun_img\n",
    "# '''\n",
    "\n",
    "# # Load the fullsized tif\n",
    "# fs_img = io.imread(tif_filename)\n",
    "# plt.imshow(fs_img)\n",
    "\n",
    "# fs_zdim = len(identifiers)\n",
    "# fs_zdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given brain region in the atlas, find the associated images and get the masked images.\n",
    "\n",
    "# # Get the indices of the label volume that contain this region.\n",
    "# region_indices = np.where(labels == region_id)\n",
    "# print(np.shape(region_indices))\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# Assuming `labels` is your 3D numpy array (volume)\n",
    "\n",
    "# def get_slices_containing_region(volume, region_id):\n",
    "#     # Identify where in the volume the region_id is found\n",
    "#     indices = np.where(volume == region_id)\n",
    "\n",
    "#     # indices is a tuple of 3 1D arrays (for the 3 dimensions of the volume)\n",
    "#     # The third element of the tuple gives the indices in the third dimension (slices)\n",
    "#     slice_indices = indices[2]\n",
    "\n",
    "#     # Get unique slice indices, as there may be multiple voxels with region_id in a single slice\n",
    "#     unique_slices = np.unique(slice_indices)\n",
    "\n",
    "#     return unique_slices\n",
    "\n",
    "# def test_slices_contiguity(slices):\n",
    "#     # Calculate the differences between adjacent elements\n",
    "#     differences = np.diff(slices)\n",
    "    \n",
    "#     # Check if all differences are 1 (which indicates contiguity)\n",
    "#     is_contiguous = np.all(differences == 1)\n",
    "    \n",
    "#     return is_contiguous\n",
    "\n",
    "# def plot_slices(labels, slices, region_id):\n",
    "#     fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "#     # Define the slice indices ensuring we don't exceed the volume boundaries\n",
    "#     slice_indices = [\n",
    "#         max(slices[0] - 1, 0),\n",
    "#         slices[0]+2,\n",
    "#         slices[len(slices) // 2],\n",
    "#         slices[-1]-2,\n",
    "#         min(slices[-1] + 1, labels.shape[2] - 1)\n",
    "#     ]\n",
    "\n",
    "#     for ax, slice_index in zip(axs, slice_indices):\n",
    "#         # Plot the grayscale volume slice\n",
    "#         ax.imshow(labels[:, :, slice_index], cmap='gray')\n",
    "        \n",
    "#         # Overlay the selected region in red\n",
    "#         overlay = np.where(labels[:, :, slice_index] == region_id, 1, np.nan)\n",
    "#         ax.imshow(overlay, cmap='Reds', alpha=1, vmin=0, vmax=1)\n",
    "        \n",
    "#         ax.set_title(f'Slice {slice_index}')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test it\n",
    "# for region_id in range(400,410):#np.unique(labels):  # I'm only using the first 5 unique labels for brevity\n",
    "#     print(f\"Region {region_id}:\")\n",
    "#     atlas_slices_with_region = get_slices_containing_region(labels, region_id)\n",
    "#     plot_slices(labels, atlas_slices_with_region, region_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''In Registration.py'''\n",
    "# def map_label_to_img(first_slice, last_slice, identifier_list, label_volume):\n",
    "#     '''Take a range of slices (first_slice to last_slice inclusive) in the label volume,\n",
    "#     and map these to the corresponding image identifiers'''\n",
    "\n",
    "#     # Get the total number of slices in the image set and label volume\n",
    "#     img_zdim = len(identifier_list)\n",
    "#     lab_zdim = label_volume.shape[2]\n",
    "\n",
    "#     # Interpolate to find the corresponding image indices\n",
    "#     first_img_ind = int(first_slice * img_zdim / lab_zdim)\n",
    "#     last_img_ind = int((last_slice+1) * img_zdim / lab_zdim)  # +1 to make the range inclusive\n",
    "\n",
    "#     # Err on the side of including more images by expanding the range\n",
    "#     first_img_ind = max(0, first_img_ind - 1)\n",
    "#     last_img_ind = min(img_zdim - 1, last_img_ind + 1)\n",
    "\n",
    "#     # Return the corresponding image identifiers\n",
    "#     return identifier_list[first_img_ind : last_img_ind + 1]  # +1 to make the range inclusive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slices containing region 400: [ 92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191]\n",
      "Image identifiers containing region 400: ['356850_415210_035800', '356850_415210_035840', '356850_415210_035880', '356850_415210_035920', '356850_415210_035960', '356850_415210_036000', '356850_415210_036040', '356850_415210_036080', '356850_415210_036120', '356850_415210_036160', '356850_415210_036200', '356850_415210_036240', '356850_415210_036280', '356850_415210_036320', '356850_415210_036360', '356850_415210_036400', '356850_415210_036440', '356850_415210_036480', '356850_415210_036520', '356850_415210_036560', '356850_415210_036600', '356850_415210_036640', '356850_415210_036680', '356850_415210_036720', '356850_415210_036760', '356850_415210_036800', '356850_415210_036840', '356850_415210_036880', '356850_415210_036920', '356850_415210_036960', '356850_415210_037000', '356850_415210_037040', '356850_415210_037080', '356850_415210_037120', '356850_415210_037160', '356850_415210_037200', '356850_415210_037240', '356850_415210_037280', '356850_415210_037320', '356850_415210_037360', '356850_415210_037400', '356850_415210_037440', '356850_415210_037480', '356850_415210_037520', '356850_415210_037560', '356850_415210_037600', '356850_415210_037640', '356850_415210_037680', '356850_415210_037720', '356850_415210_037760', '356850_415210_037800', '356850_415210_037840', '356850_415210_037880', '356850_415210_037920', '356850_415210_037960', '356850_415210_038000', '356850_415210_038040', '356850_415210_038080', '356850_415210_038120', '356850_415210_038160', '356850_415210_038200', '356850_415210_038240', '356850_415210_038280', '356850_415210_038320', '356850_415210_038360', '356850_415210_038400', '356850_415210_038440', '356850_415210_038480', '356850_415210_038520', '356850_415210_038560', '356850_415210_038600', '356850_415210_038640', '356850_415210_038680', '356850_415210_038720', '356850_415210_038760', '356850_415210_038800', '356850_415210_038840', '356850_415210_038880', '356850_415210_038920', '356850_415210_038960', '356850_415210_039000', '356850_415210_039040', '356850_415210_039080', '356850_415210_039120', '356850_415210_039160', '356850_415210_039200', '356850_415210_039240', '356850_415210_039280', '356850_415210_039320', '356850_415210_039360', '356850_415210_039400', '356850_415210_039440', '356850_415210_039480', '356850_415210_039520', '356850_415210_039560', '356850_415210_039600', '356850_415210_039640', '356850_415210_039680', '356850_415210_039720', '356850_415210_039760', '356850_415210_039800', '356850_415210_039840', '356850_415210_039880', '356850_415210_039920', '356850_415210_039960', '356850_415210_040000', '356850_415210_040040', '356850_415210_040080', '356850_415210_040120', '356850_415210_040160', '356850_415210_040200', '356850_415210_040240', '356850_415210_040280', '356850_415210_040320', '356850_415210_040360', '356850_415210_040400', '356850_415210_040440', '356850_415210_040480', '356850_415210_040520', '356850_415210_040560', '356850_415210_040600', '356850_415210_040640', '356850_415210_040680', '356850_415210_040720', '356850_415210_040760', '356850_415210_040800', '356850_415210_040840', '356850_415210_040880', '356850_415210_040920', '356850_415210_040960', '356850_415210_041000', '356850_415210_041040', '356850_415210_041080', '356850_415210_041120', '356850_415210_041160', '356850_415210_041200', '356850_415210_041240', '356850_415210_041280', '356850_415210_041320', '356850_415210_041360', '356850_415210_041400', '356850_415210_041440', '356850_415210_041480', '356850_415210_041520', '356850_415210_041560', '356850_415210_041600', '356850_415210_041640', '356850_415210_041680', '356850_415210_041720', '356850_415210_041760', '356850_415210_041800', '356850_415210_041840', '356850_415210_041880', '356850_415210_041920', '356850_415210_041960', '356850_415210_042000', '356850_415210_042040', '356850_415210_042080', '356850_415210_042120', '356850_415210_042160', '356850_415210_042200', '356850_415210_042240', '356850_415210_042280', '356850_415210_042320', '356850_415210_042360', '356850_415210_042400', '356850_415210_042440', '356850_415210_042480', '356850_415210_042520', '356850_415210_042560', '356850_415210_042600', '356850_415210_042640', '356850_415210_042680', '356850_415210_042720', '356850_415210_042760', '356850_415210_042800', '356850_415210_042840', '356850_415210_042880', '356850_415210_042920', '356850_415210_042960', '356850_415210_043000', '356850_415210_043040', '356850_415210_043080', '356850_415210_043120', '356850_415210_043160', '356850_415210_043200', '356850_415210_043240', '356850_415210_043280', '356850_415210_043320', '356850_415210_043360', '356850_415210_043400', '356850_415210_043440', '356850_415210_043480', '356850_415210_043520', '356850_415210_043560', '356850_415210_043600', '356850_415210_043640', '356850_415210_043680', '356850_415210_043720', '356850_415210_043760', '356850_415210_043800', '356850_415210_043840', '356850_415210_043880', '356850_415210_043920', '356850_415210_043960', '356850_415210_044000', '356850_415210_044040', '356850_415210_044080', '356850_415210_044120', '356850_415210_044160', '356850_415210_044200', '356850_415210_044240', '356850_415210_044280', '356850_415210_044320', '356850_415210_044360', '356850_415210_044400', '356850_415210_044440', '356850_415210_044480', '356850_415210_044520', '356850_415210_044560', '356850_415210_044600', '356850_415210_044640', '356850_415210_044680', '356850_415210_044720', '356850_415210_044760', '356850_415210_044800', '356850_415210_044840', '356850_415210_044880', '356850_415210_044920', '356850_415210_044960', '356850_415210_045000', '356850_415210_045040', '356850_415210_045080', '356850_415210_045120', '356850_415210_045160', '356850_415210_045200', '356850_415210_045240', '356850_415210_045280', '356850_415210_045320', '356850_415210_045360', '356850_415210_045400', '356850_415210_045440', '356850_415210_045480', '356850_415210_045520', '356850_415210_045560', '356850_415210_045600', '356850_415210_045640', '356850_415210_045680', '356850_415210_045720', '356850_415210_045760', '356850_415210_045800', '356850_415210_045840', '356850_415210_045880', '356850_415210_045920', '356850_415210_045960', '356850_415210_046000', '356850_415210_046040', '356850_415210_046080', '356850_415210_046120', '356850_415210_046160', '356850_415210_046200', '356850_415210_046240', '356850_415210_046280', '356850_415210_046320', '356850_415210_046360', '356850_415210_046400', '356850_415210_046440', '356850_415210_046480', '356850_415210_046520', '356850_415210_046560', '356850_415210_046600', '356850_415210_046640', '356850_415210_046680', '356850_415210_046720', '356850_415210_046760', '356850_415210_046800', '356850_415210_046840', '356850_415210_046880', '356850_415210_046920', '356850_415210_046960', '356850_415210_047000', '356850_415210_047040', '356850_415210_047080', '356850_415210_047120', '356850_415210_047160', '356850_415210_047200', '356850_415210_047240', '356850_415210_047280', '356850_415210_047320', '356850_415210_047360', '356850_415210_047400', '356850_415210_047440', '356850_415210_047480', '356850_415210_047520', '356850_415210_047560', '356850_415210_047600', '356850_415210_047640', '356850_415210_047680', '356850_415210_047720', '356850_415210_047760', '356850_415210_047800', '356850_415210_047840', '356850_415210_047880', '356850_415210_047920', '356850_415210_047960', '356850_415210_048000', '356850_415210_048040', '356850_415210_048080', '356850_415210_048120', '356850_415210_048160', '356850_415210_048200', '356850_415210_048240', '356850_415210_048280', '356850_415210_048320', '356850_415210_048360', '356850_415210_048400', '356850_415210_048440', '356850_415210_048480', '356850_415210_048520', '356850_415210_048560', '356850_415210_048600', '356850_415210_048640', '356850_415210_048680', '356850_415210_048720', '356850_415210_048760', '356850_415210_048800', '356850_415210_048840', '356850_415210_048880', '356850_415210_048920', '356850_415210_048960', '356850_415210_049000', '356850_415210_049040', '356850_415210_049080', '356850_415210_049120', '356850_415210_049160', '356850_415210_049200', '356850_415210_049240', '356850_415210_049280', '356850_415210_049320', '356850_415210_049360', '356850_415210_049400', '356850_415210_049440', '356850_415210_049480', '356850_415210_049520', '356850_415210_049560', '356850_415210_049600', '356850_415210_049640', '356850_415210_049680', '356850_415210_049720', '356850_415210_049760', '356850_415210_049800', '356850_415210_049840', '356850_415210_049880', '356850_415210_049920', '356850_415210_049960', '356850_415210_050000', '356850_415210_050040', '356850_415210_050080', '356850_415210_050120', '356850_415210_050160', '356850_415210_050200', '356850_415210_050240', '356850_415210_050280', '356850_415210_050320', '356850_415210_050360', '356850_415210_050400', '356850_415210_050440', '356850_415210_050480', '356850_415210_050520', '356850_415210_050560', '356850_415210_050600', '356850_415210_050640', '356850_415210_050680', '356850_415210_050720', '356850_415210_050760', '356850_415210_050800', '356850_415210_050840', '356850_415210_050880', '356850_415210_050920', '356850_415210_050960', '356850_415210_051000', '356850_415210_051040', '356850_415210_051080', '356850_415210_051120', '356850_415210_051160', '356850_415210_051200', '356850_415210_051240', '356850_415210_051280', '356850_415210_051320', '356850_415210_051360', '356850_415210_051400', '356850_415210_051440', '356850_415210_051480', '356850_415210_051520', '356850_415210_051560', '356850_415210_051600', '356850_415210_051640', '356850_415210_051680', '356850_415210_051720', '356850_415210_051760', '356850_415210_051800', '356850_415210_051840', '356850_415210_051880', '356850_415210_051920', '356850_415210_051960', '356850_415210_052000', '356850_415210_052040', '356850_415210_052080', '356850_415210_052120', '356850_415210_052160', '356850_415210_052200', '356850_415210_052240', '356850_415210_052280', '356850_415210_052320', '356850_415210_052360', '356850_415210_052400', '356850_415210_052440', '356850_415210_052480', '356850_415210_052520', '356850_415210_052560', '356850_415210_052600', '356850_415210_052640', '356850_415210_052680', '356850_415210_052720', '356850_415210_052760', '356850_415210_052800', '356850_415210_052840', '356850_415210_052880', '356850_415210_052920', '356850_415210_052960', '356850_415210_053000', '356850_415210_053040', '356850_415210_053080', '356850_415210_053120', '356850_415210_053160', '356850_415210_053200', '356850_415210_053240', '356850_415210_053280', '356850_415210_053320', '356850_415210_053360', '356850_415210_053400', '356850_415210_053440', '356850_415210_053480', '356850_415210_053520', '356850_415210_053560', '356850_415210_053600', '356850_415210_053640', '356850_415210_053680', '356850_415210_053720', '356850_415210_053760', '356850_415210_053800', '356850_415210_053840', '356850_415210_053880', '356850_415210_053920', '356850_415210_053960', '356850_415210_054000', '356850_415210_054040', '356850_415210_054080', '356850_415210_054120', '356850_415210_054160', '356850_415210_054200', '356850_415210_054240', '356850_415210_054280', '356850_415210_054320', '356850_415210_054360', '356850_415210_054400', '356850_415210_054440', '356850_415210_054480', '356850_415210_054520', '356850_415210_054560', '356850_415210_054600', '356850_415210_054640', '356850_415210_054680', '356850_415210_054720', '356850_415210_054760', '356850_415210_054800', '356850_415210_054840', '356850_415210_054880', '356850_415210_054920', '356850_415210_054960', '356850_415210_055000', '356850_415210_055040', '356850_415210_055080', '356850_415210_055120', '356850_415210_055160', '356850_415210_055200', '356850_415210_055240', '356850_415210_055280', '356850_415210_055320', '356850_415210_055360', '356850_415210_055400', '356850_415210_055440', '356850_415210_055480', '356850_415210_055520', '356850_415210_055560', '356850_415210_055600', '356850_415210_055640', '356850_415210_055680', '356850_415210_055720', '356850_415210_055760', '356850_415210_055800', '356850_415210_055840', '356850_415210_055880', '356850_415210_055920', '356850_415210_055960', '356850_415210_056000', '356850_415210_056040', '356850_415210_056080', '356850_415210_056120', '356850_415210_056160', '356850_415210_056200', '356850_415210_056240', '356850_415210_056280', '356850_415210_056320', '356850_415210_056360', '356850_415210_056400', '356850_415210_056440', '356850_415210_056480', '356850_415210_056520', '356850_415210_056560', '356850_415210_056600', '356850_415210_056640', '356850_415210_056680', '356850_415210_056720', '356850_415210_056760', '356850_415210_056800', '356850_415210_056840', '356850_415210_056880', '356850_415210_056920', '356850_415210_056960', '356850_415210_057000', '356850_415210_057040', '356850_415210_057080', '356850_415210_057120', '356850_415210_057160', '356850_415210_057200', '356850_415210_057240', '356850_415210_057280', '356850_415210_057320', '356850_415210_057360', '356850_415210_057400', '356850_415210_057440', '356850_415210_057480', '356850_415210_057520', '356850_415210_057560', '356850_415210_057600', '356850_415210_057640', '356850_415210_057680', '356850_415210_057720', '356850_415210_057760', '356850_415210_057800', '356850_415210_057840', '356850_415210_057880', '356850_415210_057920', '356850_415210_057960', '356850_415210_058000', '356850_415210_058040', '356850_415210_058080', '356850_415210_058120', '356850_415210_058160', '356850_415210_058200', '356850_415210_058240', '356850_415210_058280', '356850_415210_058320', '356850_415210_058360', '356850_415210_058400', '356850_415210_058440', '356850_415210_058480', '356850_415210_058520', '356850_415210_058560', '356850_415210_058600', '356850_415210_058640', '356850_415210_058680', '356850_415210_058720', '356850_415210_058760', '356850_415210_058800', '356850_415210_058840', '356850_415210_058880', '356850_415210_058920', '356850_415210_058960', '356850_415210_059000', '356850_415210_059040', '356850_415210_059080', '356850_415210_059120', '356850_415210_059160', '356850_415210_059200', '356850_415210_059240', '356850_415210_059280', '356850_415210_059320', '356850_415210_059360', '356850_415210_059400', '356850_415210_059440', '356850_415210_059480', '356850_415210_059520', '356850_415210_059560', '356850_415210_059600', '356850_415210_059640', '356850_415210_059680', '356850_415210_059720', '356850_415210_059760', '356850_415210_059800', '356850_415210_059840', '356850_415210_059880', '356850_415210_059920', '356850_415210_059960', '356850_415210_060000', '356850_415210_060040', '356850_415210_060080', '356850_415210_060120', '356850_415210_060160', '356850_415210_060200', '356850_415210_060240', '356850_415210_060280', '356850_415210_060320', '356850_415210_060360', '356850_415210_060400', '356850_415210_060440', '356850_415210_060480', '356850_415210_060520', '356850_415210_060560', '356850_415210_060600', '356850_415210_060640', '356850_415210_060680', '356850_415210_060720', '356850_415210_060760', '356850_415210_060800', '356850_415210_060840', '356850_415210_060880', '356850_415210_060920', '356850_415210_060960', '356850_415210_061000', '356850_415210_061040', '356850_415210_061080', '356850_415210_061120', '356850_415210_061160', '356850_415210_061200', '356850_415210_061240', '356850_415210_061280', '356850_415210_061320', '356850_415210_061360', '356850_415210_061400', '356850_415210_061440', '356850_415210_061480', '356850_415210_061520', '356850_415210_061560', '356850_415210_061600', '356850_415210_061640', '356850_415210_061680', '356850_415210_061720', '356850_415210_061760', '356850_415210_061800', '356850_415210_061840', '356850_415210_061880', '356850_415210_061920', '356850_415210_061960', '356850_415210_062000', '356850_415210_062040', '356850_415210_062080', '356850_415210_062120', '356850_415210_062160', '356850_415210_062200', '356850_415210_062240', '356850_415210_062280', '356850_415210_062320', '356850_415210_062360', '356850_415210_062400', '356850_415210_062440', '356850_415210_062480', '356850_415210_062520', '356850_415210_062560', '356850_415210_062600', '356850_415210_062640', '356850_415210_062680', '356850_415210_062720', '356850_415210_062760', '356850_415210_062800', '356850_415210_062840', '356850_415210_062880', '356850_415210_062920', '356850_415210_062960', '356850_415210_063000', '356850_415210_063040', '356850_415210_063080', '356850_415210_063120', '356850_415210_063160', '356850_415210_063200', '356850_415210_063240', '356850_415210_063280', '356850_415210_063320', '356850_415210_063360', '356850_415210_063400', '356850_415210_063440', '356850_415210_063480', '356850_415210_063520', '356850_415210_063560', '356850_415210_063600', '356850_415210_063640', '356850_415210_063680', '356850_415210_063720', '356850_415210_063760', '356850_415210_063800', '356850_415210_063840', '356850_415210_063880', '356850_415210_063920', '356850_415210_063960', '356850_415210_064000', '356850_415210_064040', '356850_415210_064080', '356850_415210_064120', '356850_415210_064160', '356850_415210_064200', '356850_415210_064240', '356850_415210_064280', '356850_415210_064320', '356850_415210_064360', '356850_415210_064400', '356850_415210_064440', '356850_415210_064480', '356850_415210_064520', '356850_415210_064560', '356850_415210_064600', '356850_415210_064640', '356850_415210_064680', '356850_415210_064720', '356850_415210_064760', '356850_415210_064800', '356850_415210_064840', '356850_415210_064880', '356850_415210_064920', '356850_415210_064960', '356850_415210_065000', '356850_415210_065040', '356850_415210_065080', '356850_415210_065120', '356850_415210_065160', '356850_415210_065200', '356850_415210_065240', '356850_415210_065280', '356850_415210_065320', '356850_415210_065360', '356850_415210_065400', '356850_415210_065440', '356850_415210_065480', '356850_415210_065520', '356850_415210_065560', '356850_415210_065600', '356850_415210_065640', '356850_415210_065680', '356850_415210_065720', '356850_415210_065760', '356850_415210_065800', '356850_415210_065840', '356850_415210_065880', '356850_415210_065920', '356850_415210_065960', '356850_415210_066000', '356850_415210_066040', '356850_415210_066080', '356850_415210_066120', '356850_415210_066160', '356850_415210_066200', '356850_415210_066240', '356850_415210_066280', '356850_415210_066320', '356850_415210_066360', '356850_415210_066400', '356850_415210_066440', '356850_415210_066480', '356850_415210_066520', '356850_415210_066560', '356850_415210_066600', '356850_415210_066640', '356850_415210_066680', '356850_415210_066720', '356850_415210_066760', '356850_415210_066800', '356850_415210_066840', '356850_415210_066880', '356850_415210_066920', '356850_415210_066960', '356850_415210_067000', '356850_415210_067040', '356850_415210_067080', '356850_415210_067120', '356850_415210_067160', '356850_415210_067200', '356850_415210_067240', '356850_415210_067280', '356850_415210_067320', '356850_415210_067360', '356850_415210_067400', '356850_415210_067440', '356850_415210_067480', '356850_415210_067520', '356850_415210_067560', '356850_415210_067600', '356850_415210_067640', '356850_415210_067680', '356850_415210_067720', '356850_415210_067760', '356850_415210_067800', '356850_415210_067840', '356850_415210_067880', '356850_415210_067920', '356850_415210_067960', '356850_415210_068000', '356850_415210_068040', '356850_415210_068080', '356850_415210_068120', '356850_415210_068160', '356850_415210_068200', '356850_415210_068240', '356850_415210_068280', '356850_415210_068320', '356850_415210_068360', '356850_415210_068400', '356850_415210_068440', '356850_415210_068480', '356850_415210_068520', '356850_415210_068560', '356850_415210_068600', '356850_415210_068640', '356850_415210_068680', '356850_415210_068720', '356850_415210_068760', '356850_415210_068800', '356850_415210_068840', '356850_415210_068880', '356850_415210_068920', '356850_415210_068960', '356850_415210_069000', '356850_415210_069040', '356850_415210_069080', '356850_415210_069120', '356850_415210_069160', '356850_415210_069200', '356850_415210_069240', '356850_415210_069280', '356850_415210_069320', '356850_415210_069360', '356850_415210_069400', '356850_415210_069440', '356850_415210_069480', '356850_415210_069520', '356850_415210_069560', '356850_415210_069600', '356850_415210_069640', '356850_415210_069680', '356850_415210_069720', '356850_415210_069760', '356850_415210_069800', '356850_415210_069840', '356850_415210_069880', '356850_415210_069920', '356850_415210_069960', '356850_415210_070000', '356850_415210_070040', '356850_415210_070080', '356850_415210_070120', '356850_415210_070160', '356850_415210_070200', '356850_415210_070240', '356850_415210_070280', '356850_415210_070320', '356850_415210_070360', '356850_415210_070400', '356850_415210_070440', '356850_415210_070480', '356850_415210_070520', '356850_415210_070560', '356850_415210_070600', '356850_415210_070640', '356850_415210_070680', '356850_415210_070720', '356850_415210_070760', '356850_415210_070800', '356850_415210_070840', '356850_415210_070880', '356850_415210_070920', '356850_415210_070960', '356850_415210_071000', '356850_415210_071040', '356850_415210_071080', '356850_415210_071120', '356850_415210_071160', '356850_415210_071200', '356850_415210_071240', '356850_415210_071280', '356850_415210_071320', '356850_415210_071360', '356850_415210_071400', '356850_415210_071440', '356850_415210_071480', '356850_415210_071520', '356850_415210_071560', '356850_415210_071600', '356850_415210_071640', '356850_415210_071680', '356850_415210_071720', '356850_415210_071760', '356850_415210_071800', '356850_415210_071840', '356850_415210_071880', '356850_415210_071920', '356850_415210_071960', '356850_415210_072000', '356850_415210_072040', '356850_415210_072080', '356850_415210_072120', '356850_415210_072160', '356850_415210_072200', '356850_415210_072240', '356850_415210_072280', '356850_415210_072320', '356850_415210_072360', '356850_415210_072400', '356850_415210_072440', '356850_415210_072480', '356850_415210_072520', '356850_415210_072560', '356850_415210_072600', '356850_415210_072640', '356850_415210_072680', '356850_415210_072720', '356850_415210_072760', '356850_415210_072800', '356850_415210_072840', '356850_415210_072880', '356850_415210_072920', '356850_415210_072960', '356850_415210_073000', '356850_415210_073040', '356850_415210_073080', '356850_415210_073120', '356850_415210_073160', '356850_415210_073200', '356850_415210_073240', '356850_415210_073280', '356850_415210_073320', '356850_415210_073360', '356850_415210_073400', '356850_415210_073440', '356850_415210_073480', '356850_415210_073520', '356850_415210_073560', '356850_415210_073600', '356850_415210_073640', '356850_415210_073680', '356850_415210_073720', '356850_415210_073760', '356850_415210_073800', '356850_415210_073840', '356850_415210_073880', '356850_415210_073920', '356850_415210_073960', '356850_415210_074000', '356850_415210_074040', '356850_415210_074080', '356850_415210_074120', '356850_415210_074160', '356850_415210_074200', '356850_415210_074240', '356850_415210_074280', '356850_415210_074320', '356850_415210_074360', '356850_415210_074400', '356850_415210_074440', '356850_415210_074480', '356850_415210_074520', '356850_415210_074560', '356850_415210_074600', '356850_415210_074640', '356850_415210_074680', '356850_415210_074720', '356850_415210_074760', '356850_415210_074800']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "region_id=400\n",
    "\n",
    "atlas_slices_with_region = get_slices_containing_region(labels, region_id)\n",
    "print(f\"Slices containing region {region_id}: {atlas_slices_with_region}\")\n",
    "\n",
    "# For this region, get the corresponding slices in the full-sized images\n",
    "\n",
    "# Use the first and last slices of the labels volume containing the region\n",
    "first_slice = atlas_slices_with_region[0]\n",
    "last_slice = atlas_slices_with_region[-1]\n",
    "\n",
    "# Map this to the corresponding slices in the full-sized images with map_img_to_label()\n",
    "\n",
    "region_img_identifiers = map_label_to_img(first_slice, last_slice, identifiers, labels)\n",
    "print(f\"Image identifiers containing region {region_id}: {region_img_identifiers}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "'''\n",
    "Added to Registration\n",
    "'''\n",
    "\n",
    "# def parse_itk_snap_label_file(file_path):\n",
    "#     labels = {}\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             # Skip lines that start with '#' or are empty\n",
    "#             if line.startswith(\"#\") or line.strip() == \"\":\n",
    "#                 continue\n",
    "\n",
    "#             # Split the line into fields\n",
    "#             fields = line.split()\n",
    "\n",
    "#             # Extract the index, RGB values, and label\n",
    "#             index = int(fields[0])\n",
    "#             rgb = (int(fields[1]), int(fields[2]), int(fields[3]))\n",
    "#             # Extract the label using a regular expression\n",
    "#             label = re.search(r'\"(.+)\"', line).group(1)\n",
    "\n",
    "#             # Store the extracted information in a dictionary\n",
    "#             labels[index] = {'rgb': rgb, 'label': label}\n",
    "\n",
    "\n",
    "#     return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TO UPDATE And RETURN TO REGISTRATION.py\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Have to reorganize this pipeline, so that the scaling of the mask happens just once per image\n",
    "'''\n",
    "'''\n",
    "Added to registration.py\n",
    "'''\n",
    "# def apply_region_mask(img, slice_identifier, identifiers, labels, region_id, plot=False): \n",
    "    \n",
    "#     '''Apply a mask to an image to only keep the voxels corresponding to a given region'''\n",
    "    \n",
    "#     '''  Note: This functions seems a little overloaded, but I need to be able to pass\n",
    "#       the image as it undergoes upstream image processing steps. I also need the slice_identifier and list of identifiers\n",
    "#       to map the image to the label volume. Finally, I need the labels and region_id to get the mask.\n",
    "#     '''\n",
    "\n",
    "#     # Get the index of this image with respect to\n",
    "#     (img_ind, lab_ind), this_atlas_slice = map_img_to_label(slice_identifier, identifiers, labels)\n",
    "\n",
    "#     # Get the mask this region\n",
    "#     mask = get_mask_from_label(region_id, labels)\n",
    "    \n",
    "#     # Get the corresponding slice of the mask for this image\n",
    "#     mask_slice = mask[:,:,lab_ind]\n",
    "\n",
    "#     # Use it for the mask we just created with the full-sized image\n",
    "#     masked_img = apply_mask_to_img(img, mask_slice)\n",
    "\n",
    "#     return masked_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL_PATH = 'Z://Open_data_sets/EBrains/WHS_SD_rat_atlas_v4_pack/WHS_SD_rat_atlas_v4.label'#\"your_label_file.txt\"\n",
    "\n",
    "label_data = parse_itk_snap_label_file(LABEL_PATH)\n",
    "\n",
    "keys_list = list(label_data.keys())\n",
    "\n",
    "\n",
    "# Run this part to prove to yourself that the labels are correct\n",
    "# for region_id in keys_list:#range(3):\n",
    "    \n",
    "#     region_label = label_data[region_id]['label'] # Prints the label for index 1\n",
    "#     # print(region_id, region_label)\n",
    "#     print(f\"Region {region_id}: {region_label}\")\n",
    "#     atlas_slices_with_region = get_slices_containing_region(labels, region_id)\n",
    "#     plot_slices(labels, atlas_slices_with_region, region_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1614/1614 [5:01:38<00:00, 11.21s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Now run the same operations on the GPU with clesperanto\n",
    "import pyclesperanto_prototype as cle\n",
    "\n",
    "plot=False\n",
    "subregion_masking = False\n",
    "keys_list = list(label_data.keys()) # These are the region_ids in tha atlas\n",
    "\n",
    "cell_counts = [] # storing tuples of (region_id, cell_count)\n",
    "\n",
    "\n",
    "for slice_id in tqdm(identifiers[1151:-1]):\n",
    "\n",
    "    # Use the example slice_id from midway through the stack\n",
    "    # slice_id = identifiers[1000]\n",
    "\n",
    "    # Load this image\n",
    "    full_img = io.imread(fullres_folder + slice_id + '.tif') # < 2s\n",
    "\n",
    "    # Once per image, get the slice of the labels volume that corresponds to this image\n",
    "    (img_ind, lab_ind), this_atlas_slice = map_img_to_label(slice_id, identifiers, labels)\n",
    "\n",
    "    # Scale the label slice to match the image dimensions \n",
    "    scaled_label_slice = transform.resize(this_atlas_slice, full_img.shape, order=0, preserve_range=True)\n",
    "\n",
    "    # Apply a top hat filter to the image to remove background\n",
    "    tophat_img = cle.top_hat_box(full_img, radius_x=20, radius_y=20)\n",
    "    thresh_img = cle.threshold_otsu(tophat_img)\n",
    "    lab_img = cle.voronoi_otsu_labeling(thresh_img)\n",
    "\n",
    "    cell_counts.append((slice_id, len(np.unique(lab_img))))\n",
    "\n",
    "    if(plot):\n",
    "        # Compare 3 plots side by side (Expensive operation)\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        ax[0].imshow(full_img, cmap='gray', vmin=0, vmax=2000)\n",
    "        ax[0].set_title('Full resolution')\n",
    "        ax[1].imshow(scaled_label_slice)#, cmap='gray', vmin=0, vmax=0.05)\n",
    "        ax[1].set_title('Atlas')\n",
    "        ax[2].imshow(lab_img, cmap='gray', vmin=0, vmax=1)\n",
    "        ax[2].set_title('Labelled')\n",
    "        plt.show()\n",
    "\n",
    "    if(subregion_masking):\n",
    "\n",
    "        # for region_id in keys_list:#tqdm(keys_list):#range(3):\n",
    "        for region_id in tqdm(list(np.unique(this_atlas_slice))):\n",
    "\n",
    "            region_label = label_data[region_id]['label'] # Prints the label for index 1\n",
    "\n",
    "            # Get the mask for this region (it is already scaled up to the full image size), verify..\n",
    "            region_mask = get_mask_from_label(region_id, scaled_label_slice)\n",
    "\n",
    "            # Apply the mask to the image\n",
    "            masked_img = cle.mask(lab_img, region_mask)#, masked_img)\n",
    "            cell_counts.append((slice_id, region_id,region_label,len(np.unique(masked_img))))\n",
    "\n",
    "            if(plot):\n",
    "                # Compare 3 plots side by side (Expensive operation)\n",
    "                plt.clf()\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                ax[0].imshow(full_img, cmap='gray', vmin=0, vmax=2000)\n",
    "                ax[0].set_title('Full resolution')\n",
    "                ax[1].imshow(region_mask)#, cmap='gray', vmin=0, vmax=0.05)\n",
    "                ax[1].set_title(region_label)\n",
    "                ax[2].imshow(masked_img, cmap='gray', vmin=0, vmax=1)\n",
    "                ax[2].set_title('Labelled & Masked')\n",
    "                plt.show()\n",
    "\n",
    "        # print(region_label, 'cells: ', len(np.unique(masked_img)))\n",
    "\n",
    "\n",
    "            # # Get the index of this image with respect to\n",
    "            # (img_ind, lab_ind), this_atlas_slice = map_img_to_label(slice_identifier, identifiers, labels)\n",
    "\n",
    "            # # Get the mask this region\n",
    "            # mask = get_mask_from_label(region_id, labels)\n",
    "            \n",
    "            # # Get the corresponding slice of the mask for this image\n",
    "            # mask_slice = mask[:,:,lab_ind]\n",
    "\n",
    "            # Use it for the mask we just created with the full-sized image\n",
    "            # masked_img = apply_mask_to_img(lab_img, mask_slice)\n",
    "\n",
    "\n",
    "            # # print(f\"Region {region_id}: {region_label}\")\n",
    "\n",
    "            # region_mask = apply_region_mask(lab_img, slice_id, identifiers, labels, region_id)\n",
    "\n",
    "\n",
    "            # # If region mask is binary\n",
    "            # if len(np.unique(region_mask)) == 2:\n",
    "\n",
    "                # cell_counts.append(np.nan)\n",
    "\n",
    "\n",
    "                # seg_img, pos = label_image(region_mask) #~5s\n",
    "                # cell_counts.append((slice_id, region_id, pos.shape[0]))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40808\n",
      "[['356850_415210_000000' '0' 'Clear Label' '567468']\n",
      " ['356850_415210_000000' '406' 'Secondary motor area' '22']\n",
      " ['356850_415210_000000' '427' 'Retrosplenial dysgranular area' '1581']\n",
      " ...\n",
      " ['356850_415210_046040' '152' 'Secondary auditory area, dorsal part'\n",
      "  '132']\n",
      " ['356850_415210_046040' '153' 'Secondary auditory area, ventral part'\n",
      "  '39']\n",
      " ['356850_415210_046040' '180' 'lateral olfactory tract' '9']]\n"
     ]
    }
   ],
   "source": [
    "print(len(cell_counts))\n",
    "counts_arr = np.asarray(cell_counts)\n",
    "\n",
    "cell_counts_copy = cell_counts.copy()\n",
    "\n",
    "\n",
    "#Show summary statistics of counts_arr\n",
    "print(counts_arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary so far:\n",
    "\n",
    "By sending the computations to the GPU, we've taken a ~20min per image operation down to ~40s per image. \n",
    "\n",
    "Also, it seems as though most of the most useful image processing functions are included in cle. Results more promsing than before. However, the counts and segmentations/ labels clearly aren't yet reflecting well the actua cells, so we'll need to fine-tune each of the steps in the Napari plugin. \n",
    "(installed in napari-env but not yet tested. )\n",
    "\n",
    "Currently the expensive operations are still the scaling up of the label to the actual image dimensions, but this happens only once per image, so not too bad. \n",
    "\n",
    "Since the very different intensity between regions seems to be throwing off the counts and not solved by the current version of the tophat filter, it is worth trying to perform these steps on each masked region of each image.. of course with the risk of overfitting being present. \n",
    "\n",
    "Next steps will be to try and find ideal parameters for each of the image processing steps in the cle-napari plugin, and to translate them into a Python script. -  Reminder there is a helper for this. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "assert 1==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [18:57<00:00,  5.10s/it]\n",
      "100%|██████████| 223/223 [18:46<00:00,  5.05s/it]s/it]\n",
      "100%|██████████| 223/223 [18:55<00:00,  5.09s/it]s/it]\n",
      "100%|██████████| 223/223 [17:38<00:00,  4.75s/it]s/it]\n",
      "100%|██████████| 223/223 [17:37<00:00,  4.74s/it]03s/it]\n",
      "100%|██████████| 223/223 [17:45<00:00,  4.78s/it]53s/it]\n",
      "100%|██████████| 223/223 [17:30<00:00,  4.71s/it]32s/it]\n",
      "100%|██████████| 223/223 [17:39<00:00,  4.75s/it]85s/it]\n",
      "100%|██████████| 223/223 [17:35<00:00,  4.73s/it]27s/it]\n",
      "100%|██████████| 223/223 [18:12<00:00,  4.90s/it]00s/it]\n",
      "100%|██████████| 223/223 [18:12<00:00,  4.90s/it].64s/it]\n",
      "100%|██████████| 223/223 [18:10<00:00,  4.89s/it].93s/it]\n",
      "100%|██████████| 223/223 [18:12<00:00,  4.90s/it].90s/it]\n",
      "100%|██████████| 223/223 [18:12<00:00,  4.90s/it].16s/it]\n",
      "100%|██████████| 223/223 [18:12<00:00,  4.90s/it].55s/it]\n",
      "100%|██████████| 223/223 [18:10<00:00,  4.89s/it].30s/it]\n",
      "100%|██████████| 223/223 [18:14<00:00,  4.91s/it].98s/it]\n",
      "100%|██████████| 223/223 [18:12<00:00,  4.90s/it].53s/it]\n",
      "100%|██████████| 223/223 [18:14<00:00,  4.91s/it].01s/it]\n",
      "100%|██████████| 223/223 [18:12<00:00,  4.90s/it].80s/it]\n",
      "100%|██████████| 223/223 [18:12<00:00,  4.90s/it].90s/it]\n",
      "100%|██████████| 223/223 [18:15<00:00,  4.91s/it].84s/it]\n",
      "100%|██████████| 223/223 [18:11<00:00,  4.90s/it].59s/it]\n",
      "100%|██████████| 223/223 [18:11<00:00,  4.90s/it].35s/it]\n",
      "100%|██████████| 223/223 [17:39<00:00,  4.75s/it].09s/it]\n",
      "100%|██████████| 223/223 [18:11<00:00,  4.90s/it].71s/it]\n",
      "100%|██████████| 223/223 [17:42<00:00,  4.76s/it].62s/it]\n",
      "100%|██████████| 223/223 [17:39<00:00,  4.75s/it].45s/it]\n",
      "100%|██████████| 223/223 [17:43<00:00,  4.77s/it].53s/it]\n",
      "100%|██████████| 223/223 [18:17<00:00,  4.92s/it].79s/it]\n",
      "100%|██████████| 223/223 [18:19<00:00,  4.93s/it].27s/it]\n",
      "100%|██████████| 223/223 [18:26<00:00,  4.96s/it].89s/it]\n",
      "100%|██████████| 223/223 [18:25<00:00,  4.96s/it]4.63s/it]\n",
      "100%|██████████| 223/223 [18:26<00:00,  4.96s/it]8.89s/it]\n",
      "100%|██████████| 223/223 [18:27<00:00,  4.96s/it]2.48s/it]\n",
      "100%|██████████| 223/223 [17:58<00:00,  4.84s/it]4.87s/it]\n",
      "100%|██████████| 223/223 [17:55<00:00,  4.82s/it]7.83s/it]\n",
      "100%|██████████| 223/223 [17:56<00:00,  4.83s/it]2.06s/it]\n",
      "100%|██████████| 223/223 [17:49<00:00,  4.80s/it]8.34s/it]\n",
      "100%|██████████| 223/223 [18:19<00:00,  4.93s/it]3.30s/it]\n",
      "100%|██████████| 223/223 [18:25<00:00,  4.96s/it]9.11s/it]\n",
      "100%|██████████| 223/223 [18:26<00:00,  4.96s/it]5.09s/it]\n",
      "100%|██████████| 223/223 [17:35<00:00,  4.73s/it]9.68s/it]\n",
      "100%|██████████| 223/223 [18:28<00:00,  4.97s/it]6.92s/it]\n",
      "100%|██████████| 223/223 [18:24<00:00,  4.95s/it]4.38s/it]\n",
      " 94%|█████████▍| 210/223 [17:25<01:04,  4.98s/it]8.53s/it]\n",
      "  2%|▏         | 45/2766 [14:26:35<873:20:23, 1155.47s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32me:\\Documents\\Professional\\Jupyter notebooks\\Projects\\Iordonova_lab\\brain_segmentations\\analysis\\Region Cell Counts.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# If region mask is binary\u001b[39;00m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X20sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(region_mask)) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X20sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     seg_img, pos \u001b[39m=\u001b[39m label_image(region_mask) \u001b[39m#~5s\u001b[39;00m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X20sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     cell_counts\u001b[39m.\u001b[39mappend((slice_id, region_id, pos\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X20sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39m# print(pos.shape)\u001b[39;00m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X20sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m# plt.clf()\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X20sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# else:\u001b[39;00m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X20sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m#     print('Skipping region_id: ', region_id)\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mE:\\/Documents/Professional/Jupyter notebooks/Projects/Iordonova_lab\\brain_segmentations\\segmentation\\segmentation.py:138\u001b[0m, in \u001b[0;36mlabel_image\u001b[1;34m(thresholded_image)\u001b[0m\n",
      "\u001b[0;32m    135\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mall(np\u001b[39m.\u001b[39munique(thresholded_image) \u001b[39m==\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]), \u001b[39m\"\u001b[39m\u001b[39mImage is not binary.\u001b[39m\u001b[39m\"\u001b[39m \n",
      "\u001b[0;32m    137\u001b[0m \u001b[39m# Apply regionprops to extract the positions\u001b[39;00m\n",
      "\u001b[1;32m--> 138\u001b[0m labeled_image \u001b[39m=\u001b[39m skimage\u001b[39m.\u001b[39;49mmeasure\u001b[39m.\u001b[39;49mlabel(thresholded_image)\n",
      "\u001b[0;32m    139\u001b[0m properties \u001b[39m=\u001b[39m regionprops_table(labeled_image, properties\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mcentroid\u001b[39m\u001b[39m'\u001b[39m,))\n",
      "\u001b[0;32m    140\u001b[0m positions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcolumn_stack([properties[\u001b[39m'\u001b[39m\u001b[39mcentroid-0\u001b[39m\u001b[39m'\u001b[39m], properties[\u001b[39m'\u001b[39m\u001b[39mcentroid-1\u001b[39m\u001b[39m'\u001b[39m]])\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\tyler\\Anaconda3\\envs\\brain_segmentations\\lib\\site-packages\\skimage\\_shared\\utils.py:282\u001b[0m, in \u001b[0;36mdeprecate_kwarg.__call__.<locals>.fixed_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    279\u001b[0m         kwargs[new_arg] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(old_arg)\n",
      "\u001b[0;32m    281\u001b[0m \u001b[39m# Call the function with the fixed arguments\u001b[39;00m\n",
      "\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\tyler\\Anaconda3\\envs\\brain_segmentations\\lib\\site-packages\\skimage\\measure\\_label.py:124\u001b[0m, in \u001b[0;36mlabel\u001b[1;34m(label_image, background, return_num, connectivity)\u001b[0m\n",
      "\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m _label_bool(label_image, background\u001b[39m=\u001b[39mbackground,\n",
      "\u001b[0;32m    122\u001b[0m                        return_num\u001b[39m=\u001b[39mreturn_num, connectivity\u001b[39m=\u001b[39mconnectivity)\n",
      "\u001b[0;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m clabel(label_image, background, return_num, connectivity)\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get an example identifier halfway through the list\n",
    "# slice_id = identifiers[len(identifiers) // 2]\n",
    "\n",
    "keys_list = list(label_data.keys())\n",
    "\n",
    "cell_counts = [] # storing tuples of (region_id, cell_count)\n",
    "\n",
    "for slice_id in tqdm(identifiers):\n",
    "\n",
    "    # Load this image\n",
    "    full_img = io.imread(fullres_folder + slice_id + '.tif') # < 2s\n",
    "\n",
    "    # Full image segmentation\n",
    "    tophat_img = top_hat_transform(full_img) #~40-s\n",
    "    thresh_img = threshold_image(tophat_img) #<2s\n",
    "\n",
    "# This part only took 2s so may nto be as problemeatic as I thought.\n",
    "\n",
    "# # Get the index of this image with respect to\n",
    "# (img_ind, lab_ind), this_atlas_slice = map_img_to_label(slice_identifier, identifiers, labels)\n",
    "\n",
    "# # Scale up the entire volume for this slice. \n",
    "# scaled_label = scale_mask(labels[:,:,lab_ind], thresh_img) \n",
    "# assert scaled_label.shape == full_img.shape\n",
    "\n",
    "# # '''The code below has to be in the loop, so that the mask is applied for each region\n",
    "# # HOWEVER, the scaling should happen just once per image, so it should be outside the loop\n",
    "# # '''\n",
    "\n",
    "    for region_id in tqdm(keys_list):#range(3):\n",
    "    \n",
    "        region_label = label_data[region_id]['label'] # Prints the label for index 1\n",
    "        # print(f\"Region {region_id}: {region_label}\")\n",
    "\n",
    "        region_mask = apply_region_mask(thresh_img, slice_id, identifiers, labels, region_id)\n",
    "    \n",
    "        # If region mask is binary\n",
    "        if len(np.unique(region_mask)) == 2:\n",
    "\n",
    "            seg_img, pos = label_image(region_mask) #~5s\n",
    "\n",
    "            cell_counts.append((slice_id, region_id, pos.shape[0]))\n",
    "            \n",
    "            # print(pos.shape)\n",
    "\n",
    "            # plt.clf()\n",
    "            # plt.imshow(seg_img, cmap='gray', vmin=0, vmax=1)\n",
    "            # plt.title(f\"Segmentation: {region_label}\")\n",
    "            # plt.show()\n",
    "\n",
    "        # else:\n",
    "        #     print('Skipping region_id: ', region_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\Documents\\Professional\\Jupyter notebooks\\Projects\\Iordonova_lab\\brain_segmentations\\analysis\\Region Cell Counts.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m1\u001b[39m\u001b[39m==\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mslice\u001b[39m \u001b[39min\u001b[39;00m tqdm(region_img_identifiers):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m    \u001b[39mprint\u001b[39m(\u001b[39mslice\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1==2\n",
    "for slice in tqdm(region_img_identifiers):\n",
    "\n",
    "   print(slice)\n",
    "   masked_fs_img, masked_fos_img, this_atlas_slice = process_slice(slice, plot=False)\n",
    "   \n",
    "   # Apply image filtering, transfrom and segmentation operations to masked image\n",
    "   top_hat_transformed = top_hat_transform(masked_fs_img)\n",
    "\n",
    "   seg_img, pos = segment_image(top_hat_transformed)\n",
    "   compare_segmentation(masked_fs_img, seg_img, pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the number of workers (threads) you want to use\n",
    "# num_workers = 10#os.cpu_count()\n",
    "# print('Number of workers: {}'.format(num_workers))\n",
    "\n",
    "# # Create a ThreadPoolExecutor and run the process_slice function concurrently\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     results = list(tqdm(executor.map(process_slice, identifiers), total=len(identifiers)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2766 [05:30<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'masked_fs_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Documents\\Professional\\Jupyter notebooks\\Projects\\Iordonova_lab\\brain_segmentations\\analysis\\Region Cell Counts.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m top_hat_transformed \u001b[39m=\u001b[39m top_hat_transform(full_img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m seg_img, pos \u001b[39m=\u001b[39m segment_image(top_hat_transformed)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m compare_segmentation(masked_fs_img, seg_img, pos)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'masked_fs_img' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare the timing per iteration above with instead just analyzing each image on a slice-by-slice basis\n",
    "# NOTE: No application of atlas in this test. \n",
    "for slice in tqdm(identifiers):\n",
    "\n",
    "#    print(slice)\n",
    "#    masked_fs_img, masked_fos_img, this_atlas_slice = process_slice(slice, plot=False)\n",
    "\n",
    "    full_img = load_single_image(slice, folder='neun')\n",
    "\n",
    "    # Apply image filtering, transfrom and segmentation operations to masked image\n",
    "    top_hat_transformed = top_hat_transform(full_img)\n",
    "\n",
    "    seg_img, pos = segment_image(top_hat_transformed)\n",
    "    compare_segmentation(masked_fs_img, seg_img, pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [09:11<00:00,  3.68s/it]\n",
      "100%|██████████| 150/150 [09:21<00:00,  3.74s/it]\n",
      "100%|██████████| 150/150 [09:18<00:00,  3.73s/it]\n",
      "100%|██████████| 150/150 [09:19<00:00,  3.73s/it]\n",
      "100%|██████████| 150/150 [09:20<00:00,  3.74s/it]\n",
      "100%|██████████| 150/150 [09:21<00:00,  3.74s/it]\n",
      "100%|██████████| 150/150 [09:12<00:00,  3.69s/it]\n",
      "100%|██████████| 150/150 [09:17<00:00,  3.72s/it]\n",
      "100%|██████████| 150/150 [09:13<00:00,  3.69s/it]\n",
      "100%|██████████| 150/150 [09:10<00:00,  3.67s/it]\n",
      "100%|██████████| 150/150 [09:10<00:00,  3.67s/it]\n",
      "100%|██████████| 150/150 [09:10<00:00,  3.67s/it]\n",
      "100%|██████████| 150/150 [09:11<00:00,  3.67s/it]\n",
      "100%|██████████| 150/150 [09:09<00:00,  3.66s/it]\n",
      "100%|██████████| 150/150 [09:07<00:00,  3.65s/it]\n",
      "100%|██████████| 150/150 [09:16<00:00,  3.71s/it]\n",
      "100%|██████████| 150/150 [09:11<00:00,  3.68s/it]\n",
      "100%|██████████| 150/150 [08:56<00:00,  3.58s/it]\n",
      "100%|██████████| 150/150 [08:59<00:00,  3.59s/it]\n",
      "100%|██████████| 150/150 [08:58<00:00,  3.59s/it]\n",
      "100%|██████████| 150/150 [09:03<00:00,  3.62s/it]\n",
      "100%|██████████| 150/150 [09:08<00:00,  3.66s/it]\n",
      "100%|██████████| 150/150 [09:15<00:00,  3.70s/it]\n",
      "100%|██████████| 150/150 [09:00<00:00,  3.60s/it]\n",
      "100%|██████████| 150/150 [08:54<00:00,  3.56s/it]\n",
      "100%|██████████| 150/150 [08:58<00:00,  3.59s/it]\n",
      " 74%|███████▍  | 111/150 [06:14<02:11,  3.37s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Documents\\Professional\\Jupyter notebooks\\Projects\\Iordonova_lab\\brain_segmentations\\analysis\\Region Cell Counts.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m this_crop \u001b[39min\u001b[39;00m tqdm(crop_list):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# Apply image filtering, transfrom and segmentation operations to masked image\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     top_hat_transformed \u001b[39m=\u001b[39m top_hat_transform(this_crop)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     seg_img, pos \u001b[39m=\u001b[39m segment_image(top_hat_transformed)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Documents/Professional/Jupyter%20notebooks/Projects/Iordonova_lab/brain_segmentations/analysis/Region%20Cell%20Counts.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# compare_segmentation(this_crop, seg_img, pos)\u001b[39;00m\n",
      "File \u001b[1;32mE:\\/Documents/Professional/Jupyter notebooks/Projects/Iordonova_lab\\brain_segmentations\\segmentation\\segmentation.py:83\u001b[0m, in \u001b[0;36msegment_image\u001b[1;34m(image, method, custom_threshold)\u001b[0m\n\u001b[0;32m     81\u001b[0m segmented_image \u001b[39m=\u001b[39m image \u001b[39m>\u001b[39m threshold\n\u001b[0;32m     82\u001b[0m labeled_image \u001b[39m=\u001b[39m skimage\u001b[39m.\u001b[39mmeasure\u001b[39m.\u001b[39mlabel(segmented_image)\n\u001b[1;32m---> 83\u001b[0m properties \u001b[39m=\u001b[39m regionprops_table(labeled_image, properties\u001b[39m=\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mcentroid\u001b[39;49m\u001b[39m'\u001b[39;49m,))\n\u001b[0;32m     84\u001b[0m positions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcolumn_stack([properties[\u001b[39m'\u001b[39m\u001b[39mcentroid-0\u001b[39m\u001b[39m'\u001b[39m], properties[\u001b[39m'\u001b[39m\u001b[39mcentroid-1\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m segmented_image, positions\n",
      "File \u001b[1;32mc:\\Users\\tyler\\Anaconda3\\envs\\brain_segmentations\\lib\\site-packages\\skimage\\measure\\_regionprops.py:974\u001b[0m, in \u001b[0;36mregionprops_table\u001b[1;34m(label_image, intensity_image, properties, cache, separator, extra_properties)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregionprops_table\u001b[39m(label_image, intensity_image\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    839\u001b[0m                       properties\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m    840\u001b[0m                       \u001b[39m*\u001b[39m,\n\u001b[0;32m    841\u001b[0m                       cache\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, separator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m, extra_properties\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    842\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute image properties and return them as a pandas-compatible table.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \n\u001b[0;32m    844\u001b[0m \u001b[39m    The table is a dictionary mapping column names to value arrays. See Notes\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    972\u001b[0m \n\u001b[0;32m    973\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 974\u001b[0m     regions \u001b[39m=\u001b[39m regionprops(label_image, intensity_image\u001b[39m=\u001b[39;49mintensity_image,\n\u001b[0;32m    975\u001b[0m                           cache\u001b[39m=\u001b[39;49mcache, extra_properties\u001b[39m=\u001b[39;49mextra_properties)\n\u001b[0;32m    976\u001b[0m     \u001b[39mif\u001b[39;00m extra_properties \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         properties \u001b[39m=\u001b[39m (\n\u001b[0;32m    978\u001b[0m             \u001b[39mlist\u001b[39m(properties) \u001b[39m+\u001b[39m [prop\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m prop \u001b[39min\u001b[39;00m extra_properties]\n\u001b[0;32m    979\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\tyler\\Anaconda3\\envs\\brain_segmentations\\lib\\site-packages\\skimage\\measure\\_regionprops.py:1290\u001b[0m, in \u001b[0;36mregionprops\u001b[1;34m(label_image, intensity_image, cache, coordinates, extra_properties)\u001b[0m\n\u001b[0;32m   1286\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m     label \u001b[39m=\u001b[39m i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1290\u001b[0m     props \u001b[39m=\u001b[39m RegionProperties(sl, label, label_image, intensity_image,\n\u001b[0;32m   1291\u001b[0m                              cache, extra_properties\u001b[39m=\u001b[39;49mextra_properties)\n\u001b[0;32m   1292\u001b[0m     regions\u001b[39m.\u001b[39mappend(props)\n\u001b[0;32m   1294\u001b[0m \u001b[39mreturn\u001b[39;00m regions\n",
      "File \u001b[1;32mc:\\Users\\tyler\\Anaconda3\\envs\\brain_segmentations\\lib\\site-packages\\skimage\\measure\\_regionprops.py:299\u001b[0m, in \u001b[0;36mRegionProperties.__init__\u001b[1;34m(self, slice, label, label_image, intensity_image, cache_active, extra_properties)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m\n\u001b[0;32m    298\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_image \u001b[39m=\u001b[39m label_image\n\u001b[1;32m--> 299\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_intensity_image \u001b[39m=\u001b[39m intensity_image\n\u001b[0;32m    301\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_active \u001b[39m=\u001b[39m cache_active\n\u001b[0;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\tyler\\Anaconda3\\envs\\brain_segmentations\\lib\\site-packages\\skimage\\measure\\_regionprops.py:357\u001b[0m, in \u001b[0;36mRegionProperties.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setattr__\u001b[39m(\u001b[39mself\u001b[39m, name, value):\n\u001b[1;32m--> 357\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m PROPS:\n\u001b[0;32m    358\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(PROPS[name], value)\n\u001b[0;32m    359\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Then, compare this method with the gridded approach\n",
    "\n",
    "for slice in identifiers:#tqdm(identifiers):\n",
    "\n",
    "\n",
    "    full_img = load_single_image(slice, folder='neun')\n",
    "\n",
    "    crop_list = crop_image(full_img, crop_size=(1000,1000), mode='grid')\n",
    "\n",
    "    # print(type(crop_list))\n",
    "    for this_crop in tqdm(crop_list):\n",
    "        # Apply image filtering, transfrom and segmentation operations to masked image\n",
    "        top_hat_transformed = top_hat_transform(this_crop)\n",
    "\n",
    "        seg_img, pos = segment_image(top_hat_transformed)\n",
    "        # compare_segmentation(this_crop, seg_img, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_segmentations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
